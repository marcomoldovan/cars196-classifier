{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Torch\n",
    "import torch\n",
    "# import torchinfo\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torchvision.transforms._presets import ImageClassification\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# ML-related\n",
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Default Python\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "# Other Libraries\n",
    "from PIL import Image\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import functional as F\n",
    "from torchvision.transforms.functional import InterpolationMode\n",
    "from typing import Tuple, Optional, Union\n",
    "\n",
    "def img_classification_transform(\n",
    "    img,\n",
    "    crop_size: int = 224,\n",
    "    resize_size: int = 256,\n",
    "    mean: Tuple[float, ...] = (0.485, 0.456, 0.406),\n",
    "    std: Tuple[float, ...] = (0.229, 0.224, 0.225),\n",
    "    interpolation: InterpolationMode = InterpolationMode.BILINEAR,\n",
    "    antialias: Optional[Union[str, bool]] = \"warn\"\n",
    "):\n",
    "    img = F.resize(img, resize_size, interpolation=interpolation, antialias=antialias)\n",
    "    img = F.center_crop(img, crop_size)\n",
    "    if not isinstance(img, torch.Tensor):\n",
    "        img = F.pil_to_tensor(img)\n",
    "    img = F.convert_image_dtype(img, torch.float)\n",
    "    img = F.normalize(img, mean=mean, std=std)\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StanfordCarsCustomDataset(Dataset):\n",
    "    def __init__(self, data_dir='../data/', stage='train', transforms=img_classification_transform):\n",
    "        super().__init__() \n",
    "        \n",
    "        # images\n",
    "        self.directory = f'{data_dir}/stanford-cars-dataset/cars_{stage}/cars_{stage}'\n",
    "        self.images = [os.path.join(self.directory, f) for f in os.listdir(self.directory)]\n",
    "        \n",
    "        # transforms\n",
    "        self.transforms = transforms        \n",
    "        \n",
    "        # annotations\n",
    "        cars_annos_train_mat = loadmat(f'{data_dir}/stanford-cars-dataset-meta/devkit/cars_train_annos.mat')\n",
    "        cars_annos_test_mat = loadmat(f'{data_dir}/stanford-cars-dataset-meta/cars_test_annos_withlabels (1).mat')\n",
    "        \n",
    "        self.training_image_label_dictionary, self.testing_image_label_dictionary = {}, {}\n",
    "\n",
    "        for arr in cars_annos_train_mat['annotations'][0]:\n",
    "            image, label = arr[-1][0], arr[-2][0][0] - 1\n",
    "            self.training_image_label_dictionary[image] = label\n",
    "\n",
    "        for arr in cars_annos_test_mat['annotations'][0]:\n",
    "            image, label = arr[-1][0], arr[-2][0][0] - 1\n",
    "            self.testing_image_label_dictionary[image] = label\n",
    "            \n",
    "        if stage == 'train':\n",
    "            self.image_label_dict = self.training_image_label_dictionary\n",
    "        elif stage == 'test':\n",
    "            self.image_label_dict = self.testing_image_label_dictionary\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Get image\n",
    "        image = self.images[index]\n",
    "        img_pil = Image.open(image).convert('RGB')\n",
    "        img_trans = self.transforms(img_pil)\n",
    "\n",
    "        # Parse out the label from cars_meta and cars_x_annos files\n",
    "        image_stem = image.split(\"/\")[-1]\n",
    "        img_label = self.image_label_dict[image_stem]\n",
    "\n",
    "        return img_trans, img_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "trains_ds = StanfordCarsCustomDataset(stage='train')\n",
    "train_dl = DataLoader(trains_ds, batch_size=1, shuffle=True)\n",
    "\n",
    "batch = next(iter(train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "print(batch[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "counter = 0\n",
    "\n",
    "data_dir = '../data/stanford-cars-dataset/cars_train/cars_train/'\n",
    "\n",
    "for item in os.listdir('../data/stanford-cars-dataset/cars_train/cars_train/'):\n",
    "    if not item.endswith('.jpg'):\n",
    "        os.remove(f'{data_dir}{item}')\n",
    "        \n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cars196-classifier-iE8T1ENq-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
